{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will train a deep learning natural language algorithm to try to predict the country of origin of a wine base on its description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #dataframes / data manipulation\n",
    "\n",
    "#model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#natural language toolkit\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#keras\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "#show wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to import the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930, 2)\n",
      "(129971, 2)\n"
     ]
    }
   ],
   "source": [
    "#we will select only the two columns that will be used: description and country\n",
    "columns = ['description', 'country']\n",
    "df_1 = pd.read_csv('./datasets/winemag-data_first150k.csv', usecols=columns)\n",
    "df_2 = pd.read_csv('./datasets/winemag-data-130k-v2.csv', usecols=columns)\n",
    "\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean and shape the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150930 entries, 0 to 150929\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   country      150925 non-null  object\n",
      " 1   description  150930 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "--------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129971 entries, 0 to 129970\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   country      129908 non-null  object\n",
      " 1   description  129971 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#looking for null entries to be removed\n",
    "print(df_1.info())\n",
    "print('--------------------------------------')\n",
    "print(df_2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280833, 2)\n"
     ]
    }
   ],
   "source": [
    "#there seem to be some null values for countries in both datasets\n",
    "#we can see that by comparing the total entries with the non-null number\n",
    "#we'll drop them off\n",
    "df_1.dropna(axis=0, inplace=True)\n",
    "df_2.dropna(axis=0, inplace=True)\n",
    "\n",
    "#then we'll concatenate both into one dataframe\n",
    "df = pd.concat([df_1, df_2])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>280833</td>\n",
       "      <td>280833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50</td>\n",
       "      <td>169370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>US</td>\n",
       "      <td>A little bit funky and unsettled when you pop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>116901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country                                        description\n",
       "count   280833                                             280833\n",
       "unique      50                                             169370\n",
       "top         US  A little bit funky and unsettled when you pop ...\n",
       "freq    116901                                                  7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what we got so far\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special characters\n",
    "df['description'] = df['description'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "\n",
    "#converting everything o lowercase so there's no distinction between the same word\n",
    "df['description'] = df['description'].apply(lambda x: x.lower())\n",
    "\n",
    "#now to remove the stopwords (the ones that don't affect the result)\n",
    "stop_words = stopwords.words('english')\n",
    "df['description'] = df['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "#lemmatizing (removing conjugation to convert all the words to their base form)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['description'] = df['description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "#encode the labels\n",
    "df['country'] = df['country'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tremendous varietal wine hail oakville aged th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ripe aroma fig blackberry cassis softened swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mac watson honor memory wine made mother treme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>spent month new french oak incorporates fruit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>top wine la b gude named highest point vineyar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>deep dense pure opening bell toro winner aroma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>slightly gritty black fruit aroma include swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>lush cedary black fruit aroma luxe offer note ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>named vineyard formerly bottled delancellotti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>producer source two block vineyard wine one hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>elegance complexity structure come together dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>year old vine supple well balanced effort blen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>standout even terrific lineup release patricia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>wine peak condition tannin secondary flavor do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>sophisticated mix mineral acid tart fruit sedu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description\n",
       "0         0  tremendous varietal wine hail oakville aged th...\n",
       "1         1  ripe aroma fig blackberry cassis softened swee...\n",
       "2         0  mac watson honor memory wine made mother treme...\n",
       "3         0  spent month new french oak incorporates fruit ...\n",
       "4         2  top wine la b gude named highest point vineyar...\n",
       "5         1  deep dense pure opening bell toro winner aroma...\n",
       "6         1  slightly gritty black fruit aroma include swee...\n",
       "7         1  lush cedary black fruit aroma luxe offer note ...\n",
       "8         0  named vineyard formerly bottled delancellotti ...\n",
       "9         0  producer source two block vineyard wine one hi...\n",
       "10        3  elegance complexity structure come together dr...\n",
       "11        0  year old vine supple well balanced effort blen...\n",
       "12        0  standout even terrific lineup release patricia...\n",
       "13        2  wine peak condition tannin secondary flavor do...\n",
       "14        0  sophisticated mix mineral acid tart fruit sedu..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's see how our dataframe looks\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  31150\n"
     ]
    }
   ],
   "source": [
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['description'], df['country'])\n",
    "\n",
    "#check how many unique words we have\n",
    "vocab_size = len(set(' '.join(X_train).split()))\n",
    "print('Vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7803 28525 23894 ...     0     0     0]\n",
      " [11256 30594 29370 ...     0     0     0]\n",
      " [13708 29576 14298 ...     0     0     0]\n",
      " ...\n",
      " [22507 25900 19741 ...     0     0     0]\n",
      " [27456    55 14298 ...     0     0     0]\n",
      " [27456 29354  6014 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "#encoding the words with numbers for the model to be able to process them\n",
    "#each unique word turns into an integer, then converted to a binary vector\n",
    "train = [one_hot(d, vocab_size) for d in X_train]\n",
    "test = [one_hot(d, vocab_size) for d in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding every description to the length of 100 words\n",
    "max_length = 100\n",
    "padded_train = pad_sequences(train, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 32)           996800    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,016,690\n",
      "Trainable params: 1,016,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#embedding size\n",
    "embedding_size = 32\n",
    "#number of classes - count the number of countries available\n",
    "num_classes = df['country'].nunique()\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_length))\n",
    "#bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6582/6582 [==============================] - 168s 25ms/step - loss: 0.8814 - accuracy: 0.7231\n",
      "Epoch 2/10\n",
      "6582/6582 [==============================] - 166s 25ms/step - loss: 0.5591 - accuracy: 0.8141\n",
      "Epoch 3/10\n",
      "6582/6582 [==============================] - 223s 34ms/step - loss: 0.4377 - accuracy: 0.8564\n",
      "Epoch 4/10\n",
      "6582/6582 [==============================] - 247s 38ms/step - loss: 0.3681 - accuracy: 0.8805\n",
      "Epoch 5/10\n",
      "6582/6582 [==============================] - 249s 38ms/step - loss: 0.3203 - accuracy: 0.8955\n",
      "Epoch 6/10\n",
      "6582/6582 [==============================] - 269s 41ms/step - loss: 0.2833 - accuracy: 0.9075\n",
      "Epoch 7/10\n",
      "6582/6582 [==============================] - 241s 37ms/step - loss: 0.2542 - accuracy: 0.9171\n",
      "Epoch 8/10\n",
      "6582/6582 [==============================] - 266s 40ms/step - loss: 0.2294 - accuracy: 0.9253\n",
      "Epoch 9/10\n",
      "6582/6582 [==============================] - 299s 45ms/step - loss: 0.2097 - accuracy: 0.9320\n",
      "Epoch 10/10\n",
      "6582/6582 [==============================] - 262s 40ms/step - loss: 0.1918 - accuracy: 0.9377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222a1e481f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_train, y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195/2195 [==============================] - 20s 8ms/step - loss: 0.4144 - accuracy: 0.8941\n",
      "Accuracy: 89.408767\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
